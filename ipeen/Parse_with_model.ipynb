{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from tools import GetAgent, GetLastPage, GetPhoneNum, DownloadImg, CreatePages, GetCategory, GetImgUrl, GetNameAndLink, GetAddr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為是要抓取台灣的店家清單，所以先從搜尋的首頁抓出總頁數，再把頁數建立成一個list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11246\n"
     ]
    }
   ],
   "source": [
    "main_url = 'http://www.ipeen.com.tw/search/taiwan/000/1-100-0-0/'\n",
    "result = requests.get(main_url)\n",
    "contents = soup(result.text, 'lxml')\n",
    "last_page = contents.find_all('a',{'data-label':'最尾頁'})\n",
    "last_page_url = last_page[0].attrs['href']\n",
    "page_count = last_page_url.split('=')[1]\n",
    "url_list = []\n",
    "for count in range(1, int(page_count)):\n",
    "    url_list.append(last_page_url.split('=')[0]+str(count))\n",
    "print(len(url_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從頁數的list中，開始針對各分頁進行爬蟲，並把爬出來的結果寫入檔案中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for this_page in url_list:\n",
    "    page_cont = requests.get(this_page, GetAgent())\n",
    "    cont = soup(page_cont.text, 'lxml')\n",
    "    print(this_page)\n",
    "    articles = cont.find_all('article')\n",
    "    with open('ipeen_detail.csv', 'a+', encoding ='utf8') as record:\n",
    "        this_page = []\n",
    "        for article in articles:\n",
    "            addr = GetAddr(article)\n",
    "            img = GetImgUrl(article)\n",
    "            name = img['name']\n",
    "            link = img['link']\n",
    "            print(img)\n",
    "            phone = ''\n",
    "            if 'phone' in img.keys():\n",
    "                phone = img['phone']\n",
    "            categories = GetCategory(article)\n",
    "            cate1 = categories['category1']\n",
    "            cate2 = categories['category2']\n",
    "            all_info = name+','+addr+','+phone+','+cate1+','+cate2+'\\n'\n",
    "            if (len(all_info) == 0):\n",
    "                this_page.append(all_info)\n",
    "            elif all_info not in this_page:\n",
    "                this_page.append(all_info)\n",
    "            t = int(random.random() * 10)\n",
    "            time.sleep(t)\n",
    "        for p in this_page:\n",
    "            record.write(p)\n",
    "        record.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
